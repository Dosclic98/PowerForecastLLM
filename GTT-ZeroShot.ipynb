{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn (from -r requirements.txt (line 1))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 3))\n",
      "  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 4))\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting astral (from -r requirements.txt (line 5))\n",
      "  Using cached astral-3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 6))\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting auto_mix_prep==0.2.0 (from -r requirements.txt (line 7))\n",
      "  Using cached auto_mix_prep-0.2.0-py3-none-any.whl\n",
      "Collecting tensorflow==2.13.0 (from -r requirements.txt (line 8))\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pydub (from auto_mix_prep==0.2.0->-r requirements.txt (line 7))\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 3))\n",
      "  Using cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow==2.13.0->-r requirements.txt (line 8)) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow==2.13.0->-r requirements.txt (line 8)) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.13.0->-r requirements.txt (line 8)) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 4))\n",
      "  Using cached contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 4))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 4))\n",
      "  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 4))\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib->-r requirements.txt (line 4))\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r requirements.txt (line 4))\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.0->-r requirements.txt (line 8)) (0.44.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r requirements.txt (line 8))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached astral-3.2-py3-none-any.whl (38 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pytz, pydub, libclang, flatbuffers, wrapt, urllib3, tzdata, typing-extensions, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyparsing, pyasn1, protobuf, pillow, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, kiwisolver, keras, joblib, idna, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, auto_mix_prep, astunparse, astral, absl-py, werkzeug, scipy, rsa, requests, pyasn1-modules, pandas, h5py, contourpy, scikit-learn, requests-oauthlib, matplotlib, google-auth, seaborn, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 8.29.0 requires typing-extensions>=4.6; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astral-3.2 astunparse-1.6.3 auto_mix_prep-0.2.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 contourpy-1.3.0 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.54.1 gast-0.4.0 google-auth-2.35.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.67.0 h5py-3.12.1 idna-3.10 joblib-1.4.2 keras-2.13.1 kiwisolver-1.4.7 libclang-18.1.1 markdown-3.7 matplotlib-3.9.2 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.4.0 pandas-2.2.3 pillow-11.0.0 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydub-0.25.1 pyparsing-3.2.0 pytz-2024.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9 scikit-learn-1.5.2 scipy-1.14.1 seaborn-0.13.2 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 threadpoolctl-3.5.0 typing-extensions-4.5.0 tzdata-2024.2 urllib3-2.2.3 werkzeug-3.0.6 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 17:23:29.027263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 17:23:29.751548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "from src.apis import zeroshot_api\n",
    "import pprint\n",
    "import datetime\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"./data\"\n",
    "\n",
    "###choose GTT model variant\n",
    "modelchoice = 'small'\n",
    "modelpath = f'./GTT/checkpoints/GTT-{modelchoice}'\n",
    "\n",
    "###whether do 1st-order differencing before prediction, sometimes set autodiff=True will improve prediction accuracy\n",
    "autodiff = True\n",
    "PLOT = False\n",
    "splits = [('2016-02-01', '2016-03-01'), ('2016-03-01', '2016-04-01'), ('2016-04-01', '2016-05-01'),\n",
    "          ('2016-05-01', '2016-06-01'), ('2016-06-01', '2016-07-01'), ('2016-07-01', '2016-08-01'),\n",
    "          ('2016-08-01', '2016-09-01'), ('2016-09-01', '2016-10-01'), ('2016-10-01', '2016-11-01')]\n",
    "experiments = [(96,24), (192,24), (288,24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average results with prediction length 1 and context length 95\n",
      "MAE: 494.72836960632816\n",
      "RMSE: 494.72836960632816\n",
      "MAPE: 9.032356368205487\n",
      "Average results with prediction length 1 and context length 191\n",
      "MAE: 491.1343894576999\n",
      "RMSE: 491.1343894576999\n",
      "MAPE: 9.739039633814455\n",
      "Average results with prediction length 1 and context length 287\n",
      "MAE: 518.145866973941\n",
      "RMSE: 518.145866973941\n",
      "MAPE: 9.832997301720635\n"
     ]
    }
   ],
   "source": [
    "dfCompl = pd.read_csv(f\"{path}/train.csv\", parse_dates=[\"date\"], index_col=None)\n",
    "for exp in experiments:\n",
    "    maes = []\n",
    "    rmses = []\n",
    "    mapes = []\n",
    "\n",
    "    ###define prediction length, i.e., number of forecast steps\n",
    "    ###define prediction start step, it's N to last step in your data\n",
    "    pred_len = pred_start =  exp[1]\n",
    "    data_len = exp[0]\n",
    "    #if i >= 2:\n",
    "    #    data_len = 3 * pred_len\n",
    "\n",
    "    for split in splits:\n",
    "        dfSplit = dfCompl.iloc[(dfCompl[\"date\"] > pd.to_datetime(split[0]).tz_localize(pytz.timezone('US/Eastern'))).values].reset_index(drop=True)\n",
    "        dfSplit = dfCompl.iloc[(dfCompl[\"date\"] < pd.to_datetime(split[1]).tz_localize(pytz.timezone('US/Eastern'))).values].reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "        df = dfSplit.iloc[range(len(dfSplit)-(data_len),len(dfSplit))]\n",
    "        df = df.reset_index(drop=True)\n",
    "    \n",
    "        timefeat = df.columns[0]\n",
    "        targets = [df.columns[1]]\n",
    "        covariates = df.columns[range(2,len(df.columns))].array\n",
    "\n",
    "        res = zeroshot_api.forecast(df, targets, covariates, timefeat, pred_len, pred_start, modelpath, autodiff=autodiff)\n",
    "        if PLOT and res['ret'] == 'success':\n",
    "            zeroshot_api.plot_res(res)\n",
    "\n",
    "        trueData = np.array(res[\"targets\"][0][\"values\"][(data_len-pred_len):])\n",
    "        preds = np.array(res[\"targets\"][0][\"preds\"])\n",
    "\n",
    "        MAE = np.mean(np.abs(trueData - preds))\n",
    "        RMSE = np.sqrt(np.mean((trueData - preds)**2))\n",
    "        MAPE = np.mean(np.abs((trueData - preds) / trueData)) * 100\n",
    "\n",
    "        maes.append(MAE)\n",
    "        rmses.append(RMSE)\n",
    "        mapes.append(MAPE)\n",
    "\n",
    "    print(f\"Average results with prediction length {pred_len} and context length {data_len - pred_len}\")\n",
    "    print(f\"MAE: {np.mean(maes)}\")\n",
    "    print(f\"RMSE: {np.mean(rmses)}\")\n",
    "    print(f\"MAPE: {np.mean(mapes)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
